{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dronespotter \n",
    "![demo](Demo.jpg)\n",
    "\n",
    "### STEP 1\n",
    "1. Importing the necessary libraries \n",
    "2. Verifying we have the correct version of PyTorch installed \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install simple-image-download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labelImg in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (1.8.6)\n",
      "Requirement already satisfied: pyqt5 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from labelImg) (5.15.9)\n",
      "Requirement already satisfied: lxml in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from labelImg) (4.9.2)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.11 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from pyqt5->labelImg) (12.12.1)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from pyqt5->labelImg) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install labelImg #this does not work on python 3.11 for the love of god will they update this utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (2.0.1+cu117)\n",
      "Requirement already satisfied: filelock in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lukes\\desktop\\drone object detection\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 \n",
    "1. Downloading images to create a dataset\n",
    "2. Annotation using LabelImg to create a dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "from simple_image_download import simple_image_download as simp \n",
    "response=simp.Downloader\n",
    "keywords=[\"drone\"]\n",
    "for kw in keywords: \n",
    "    response().download(kw,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelImg ##this does not work yet on python 3.11(and knowing the devs it probably never will), Future me please use this opportunity to show off how to actually use labelimg on python 3.9 pls, thanks in advance -past sankie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 \n",
    "1. Training the model\n",
    "2. Yolo: Calls The YOLOV8 model from ultralytics\n",
    "3. Detect: Calls The Object Detection Version \n",
    "4. Train: Puts Yolov8 into training mode\n",
    "5. Data: Name/Location Of .YAML file that contains the source of data \n",
    "6. Model: Which Specific Yolov8 model you'd like to use \n",
    "7. epochs: Total Number Of Iterations Of The training Data \n",
    "8. Imgsz: autmatically resizes the images to 640x640p for faster training \n",
    "9. Batch: Specifiy the amount of VRAM to be used (only on CUDA compatible GPUs)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect train data=data.yaml model=yolov8m.pt epochs=100 imgsz=640 batch=2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 \n",
    "1. Running the inference \n",
    "2. Go to runs-> detect -> trainx (x representing any number)\n",
    "3. Go to the weights folder \n",
    "4. Copy the best.pt file and paste it into the main folder \n",
    "5. Task: What do you want it to do, in our case we want it to detect something\n",
    "6. Mode: Puts model into prediction mode \n",
    "7. Model: Name of weights file, by default it's best.pt \n",
    "8. Show: WOULD YOU LIKE TO SEE IT HAPPEN? (spoiler alert this usually crashes, i donot know why ¯\\_(ツ)_/¯) \n",
    "9. Source: Source of input video or image to be tested \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect predict model=med.pt source='drone1.mp4' show=True conf=0.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a live inference \n",
    "The code below shows how to run a live inference, in this case source is a webcam\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('med.pt')\n",
    "model.predict(source=\"0\", show=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDITIONAL INFO \n",
    "because, developers are the way they are it's a guarnteed fact that cuda, cdnn or ultralytics modules may not be compatible with certain gpus, devices and even in between sessions, future me: please use this incredible totally not frequent occurence of things not working in the tech space to kindly demonstrate why google cloud is such a meta for development, thanks in advance - past sankie \n",
    "https://colab.research.google.com/drive/1TiRQ4_6LltXy5a5L-cjSmRV4ddDk3DDr?usp=sharing\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
